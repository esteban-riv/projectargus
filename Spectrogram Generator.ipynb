{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram and Power Spectrum Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the project use Deep Learning to automatize feature extraction. For that propourse we convert waveforms to spectrograms images. This notebook can be avoid beacuse it data is provided in the file \"spectrograms.zip\"\n",
    "\n",
    "<a href=\"https://colab.research.google.com/drive/1hP9gDx5AkAymNtzz9ZdeJgjlLtmZ0C-p#scrollTo=3-ruJnWwzFxn\">Colab</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Scripts.datosadash import datosADASH\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Nombre</th>\n",
       "      <th>diagnostico</th>\n",
       "      <th>Id_Estado_Activo_fixed</th>\n",
       "      <th>time</th>\n",
       "      <th>max_mms</th>\n",
       "      <th>machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S3-Ventilador M38</td>\n",
       "      <td>Motor: Activo en buen estado.\\n Ventilador: S...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-18 12:38:26.205</td>\n",
       "      <td>9.2617</td>\n",
       "      <td>S3-M38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S3-Ventilador M38</td>\n",
       "      <td>Motor: Activo en buen estado.\\n Ventilador: S...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-18 12:38:41.249</td>\n",
       "      <td>6.4828</td>\n",
       "      <td>S3-M38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>S3-Ventilador M38</td>\n",
       "      <td>Motor: Activo en buen estado.\\n Ventilador: S...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-18 12:38:57.866</td>\n",
       "      <td>7.4407</td>\n",
       "      <td>S3-M38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>S3-Ventilador M38</td>\n",
       "      <td>Motor: Activo en buen estado.\\n Ventilador: S...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-18 12:39:08.660</td>\n",
       "      <td>6.9886</td>\n",
       "      <td>S3-M38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>S3-Ventilador M38</td>\n",
       "      <td>Motor: Activo en buen estado.\\n Ventilador: S...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-18 12:39:20.397</td>\n",
       "      <td>7.3701</td>\n",
       "      <td>S3-M38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Nombre  \\\n",
       "0           0  S3-Ventilador M38   \n",
       "1           1  S3-Ventilador M38   \n",
       "2           2  S3-Ventilador M38   \n",
       "3           3  S3-Ventilador M38   \n",
       "4           4  S3-Ventilador M38   \n",
       "\n",
       "                                         diagnostico  Id_Estado_Activo_fixed  \\\n",
       "0   Motor: Activo en buen estado.\\n Ventilador: S...                     2.0   \n",
       "1   Motor: Activo en buen estado.\\n Ventilador: S...                     2.0   \n",
       "2   Motor: Activo en buen estado.\\n Ventilador: S...                     2.0   \n",
       "3   Motor: Activo en buen estado.\\n Ventilador: S...                     2.0   \n",
       "4   Motor: Activo en buen estado.\\n Ventilador: S...                     2.0   \n",
       "\n",
       "                      time  max_mms machine  \n",
       "0  2019-06-18 12:38:26.205   9.2617  S3-M38  \n",
       "1  2019-06-18 12:38:41.249   6.4828  S3-M38  \n",
       "2  2019-06-18 12:38:57.866   7.4407  S3-M38  \n",
       "3  2019-06-18 12:39:08.660   6.9886  S3-M38  \n",
       "4  2019-06-18 12:39:20.397   7.3701  S3-M38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to get a dataframe with the relation between every spectrogram\n",
    "# and the label. This label is the diagnostic made be the analyst. We import\n",
    "# the csv \"diagnosis.csv\" where this information is saved. Then we create\n",
    "# an empty dataframe to write the information of the spectrogram. These spectrogram\n",
    "# will be merged with the diagnostics csv.\n",
    "\n",
    "diag = pd.read_csv('Data/diagnosis.csv')\n",
    "spectro_diag = pd.DataFrame(columns=['file','time'])\n",
    "\n",
    "diag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the folder where waveforms are and get machine, points and files\n",
    "path = 'Data/Export'\n",
    "\n",
    "folder = datosADASH(path)\n",
    "machines = folder.getmachines()\n",
    "points = folder.getpoints()\n",
    "files = folder.getfiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-1d928d18915d>:33: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  plt.pcolormesh(t, f, Sxx)\n",
      "<ipython-input-32-1d928d18915d>:42: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"figsize\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  fig.savefig(filename, transparent=True, pad_inches=0.0,\n"
     ]
    }
   ],
   "source": [
    "# Spectrograms will be created with Scypy, it takes few minutes to generate them.\n",
    "\n",
    "# First we create a folder to save Spectrograms\n",
    "try:\n",
    "    os.mkdir('Data/Export/Spectrograms')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# And the create Spectrograms\n",
    "for machine, points_iter in points.items():\n",
    "    filteredmachines = list(filter(lambda x: machine in x, files))\n",
    "    for iteration, point in enumerate(points_iter):\n",
    "        acc_spec_text = \"Aceleracion - Forma\"\n",
    "        filteredpoints = list(filter(lambda x: point in x, filteredmachines))\n",
    "        filteredcsv = list(filter(lambda x:\".csv\" in x, filteredpoints))\n",
    "                        \n",
    "        # Get files by type of measurement\n",
    "        accspec = list(filter(lambda x:acc_spec_text in x, filteredcsv))\n",
    "                \n",
    "                \n",
    "        for filetime in accspec:\n",
    "            forma = pd.read_csv(filetime, skiprows=1,\n",
    "                                        delimiter=\";\", encoding = \"ISO-8859-1\")\n",
    "            forma = forma.rename(columns={'time[ms]':'time',\n",
    "                                                  ' amplitude[g]':'amplitude'})\n",
    "            date = pd.read_csv(filetime, nrows=0,\n",
    "                                        delimiter=\";\", encoding = \"ISO-8859-1\").columns[1][6:]\n",
    "            fs = 12000\n",
    "            fig,ax = plt.subplots(1)\n",
    "            fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "            ax.axis('off')\n",
    "            # Create the spetrogrmas\n",
    "            f, t, Sxx = signal.spectrogram(forma['amplitude'], fs)\n",
    "            plt.pcolormesh(t, f, Sxx)\n",
    "            ax.axis('tight')\n",
    "            ax.axis('off')\n",
    "            date_sub = re.sub('[^A-Za-z0-9]+','', date)\n",
    "                    \n",
    "            filename = str(date_sub) + \"_\" + str(machine) + \"_\" + str(point)\n",
    "            folder = \"Spectrograms\"\n",
    "            filename = os.path.join(path, folder, filename)\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            fig.savefig(filename, transparent=True, pad_inches=0.0,\n",
    "                                figsize=(96/96, 96/96), dpi=96)\n",
    "            plt.close()\n",
    "            \n",
    "            spectro_diag = spectro_diag.append({\"file\":filename,\n",
    "                                                \"time\":date,\n",
    "                                                \"machine\":machine\n",
    "                                                }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create a dataframe where images and status \n",
    "# are correlated.\n",
    "\n",
    "def sorted_index_by_time(df):\n",
    "    \"\"\"Function for sorting values\n",
    "    by time and set it to index\"\"\"\n",
    "    df = df.sort_values(['time'])\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    return df\n",
    "\n",
    "diag = sorted_index_by_time(diag)\n",
    "spectro_diag = sorted_index_by_time(spectro_diag)\n",
    "\n",
    "merged_diagnostic = pd.merge_asof(spectro_diag, diag, on=\"time\", by=['machine'],\n",
    "                  tolerance=pd.Timedelta('10 days'), direction='nearest')\n",
    "\n",
    "merged_diagnostic[['file', 'time', 'machine','Nombre', 'diagnostico',\n",
    "       'Id_Estado_Activo_fixed']]\n",
    "\n",
    "merged_diagnostic = merged_diagnostic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep learning will need to move the images to\n",
    "# one folder for the two labels. \n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Spectrograms/class_a')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Spectrograms/class_b')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "merged_diagnostic.file = merged_diagnostic.file + '.png'\n",
    "\n",
    "merged_diagnostic['filecut'] = merged_diagnostic['file'].str.split('/').str[-1]\n",
    "\n",
    "folder_a = os.path.join(path, 'Spectrograms/class_a/')\n",
    "folder_b = os.path.join(path, 'Spectrograms/class_b/')\n",
    "\n",
    "for index, row in merged_diagnostic.iterrows():\n",
    "    filecut = row.filecut\n",
    "    file = row.file\n",
    "    if row.Id_Estado_Activo_fixed == 1.0:\n",
    "        final_filename = folder_a + filecut\n",
    "        os.rename(file, final_filename)\n",
    "    if row.Id_Estado_Activo_fixed > 1:\n",
    "        final_filename = folder_b + filecut\n",
    "        os.rename(file, final_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep learning will need to move the images to\n",
    "# one folder for the two labels. \n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Spectrograms/prediction')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "import os, glob\n",
    "for filename in glob.glob(\"Data/Export/Spectrograms/2021*\"):\n",
    "    filename_end = filename.split('/')[-1]\n",
    "    path_pre = \"Data/Export/Spectrograms/prediction/\"\n",
    "    final_filename= os.path.join(path_pre, filename_end)\n",
    "    os.rename(filename, final_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelets\n",
    "\n",
    "We also are going to use power spectrums, the way to create them is similar to Spectrograms. In this case pywt library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-e7232d4294fd>:60: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"figsize\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  f.savefig(filename, transparent=True, pad_inches=0.0,\n"
     ]
    }
   ],
   "source": [
    "# First we create a folder to save Wavelets\n",
    "try:\n",
    "    os.mkdir('Data/Export/Wavelets')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Wavelets and power spectrums are generated with pywt\n",
    "for machine, points_iter in points.items():\n",
    "    filteredmachines = list(filter(lambda x: machine in x, files))\n",
    "    for iteration, point in enumerate(points_iter):\n",
    "        acc_spec_text = \"Aceleracion - Forma\"\n",
    "        filteredpoints = list(filter(lambda x: point in x, filteredmachines))\n",
    "        filteredcsv = list(filter(lambda x:\".csv\" in x, filteredpoints))\n",
    "                        \n",
    "        # Get files by type of measurement\n",
    "        accspec = list(filter(lambda x:acc_spec_text in x, filteredcsv))\n",
    "                \n",
    "                \n",
    "        for filetime in accspec:\n",
    "            forma = pd.read_csv(filetime, skiprows=1,\n",
    "                                        delimiter=\";\", encoding = \"ISO-8859-1\")\n",
    "            forma = forma.rename(columns={'time[ms]':'time',\n",
    "                                                  ' amplitude[g]':'amplitude'})\n",
    "            date = pd.read_csv(filetime, nrows=0,\n",
    "                                        delimiter=\";\", encoding = \"ISO-8859-1\").columns[1][6:]\n",
    "            \n",
    "            \n",
    "            time = forma['time']\n",
    "            sst = forma['amplitude']\n",
    "            dt = time[1] - time[0]\n",
    "\n",
    "            wavelet = 'cmor1.5-1.0'\n",
    "            scales = np.arange(1, 128)\n",
    "\n",
    "            [cfs, frequencies] = pywt.cwt(sst, scales, wavelet, dt)\n",
    "            power = (abs(cfs)) ** 2\n",
    "\n",
    "            period = 1. / frequencies\n",
    "            levels = [0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8]\n",
    "            dpi = 96\n",
    "\n",
    "\n",
    "            f, ax = plt.subplots(1, figsize=(400/dpi, 400/dpi))\n",
    "            f.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "            ax.contourf(time, np.log2(period), np.log2(power), np.log2(levels),\n",
    "                        extend='both')\n",
    "            ax.invert_yaxis()\n",
    "            ax.axis('off')\n",
    "            \n",
    "            \n",
    "            date_sub = re.sub('[^A-Za-z0-9]+','', date)    \n",
    "             \n",
    "            filename = str(date_sub) + \"_\" + str(machine) + \"_\" + str(point)\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            folder = \"Wavelets\"\n",
    "            filename = os.path.join(path, folder, filename)\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            \n",
    "            \n",
    "            f.savefig(filename, transparent=True, pad_inches=0.0,\n",
    "                                figsize=(96/96, 96/96), dpi=96)\n",
    "            \n",
    "            plt.close()\n",
    "            \n",
    "            \n",
    "            spectro_diag = spectro_diag.append({\"file\":filename,\n",
    "                                                \"time\":date,\n",
    "                                                \"machine\":machine\n",
    "                                                }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create a dataframe where images and status \n",
    "# are correlated.\n",
    "\n",
    "def sorted_index_by_time(df):\n",
    "    \"\"\"Function for sorting values\n",
    "    by time and set it to index\"\"\"\n",
    "    df = df.sort_values(['time'])\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    return df\n",
    "\n",
    "diag = sorted_index_by_time(diag)\n",
    "spectro_diag = sorted_index_by_time(spectro_diag)\n",
    "\n",
    "merged_diagnostic = pd.merge_asof(spectro_diag, diag, on=\"time\", by=['machine'],\n",
    "                  tolerance=pd.Timedelta('10 days'), direction='nearest')\n",
    "\n",
    "merged_diagnostic[['file', 'time', 'machine','Nombre', 'diagnostico',\n",
    "       'Id_Estado_Activo_fixed']]\n",
    "\n",
    "merged_diagnostic = merged_diagnostic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep learning will need to move the images to\n",
    "# one folder for every label. \n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Wavelets/class_a')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Wavelets/class_b')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "merged_diagnostic.file = merged_diagnostic.file + '.png'\n",
    "\n",
    "merged_diagnostic['filecut'] = merged_diagnostic['file'].str.split('/').str[-1]\n",
    "\n",
    "folder_a = os.path.join(path, 'Wavelets/class_a/')\n",
    "folder_b = os.path.join(path, 'Wavelets/class_b/')\n",
    "\n",
    "for index, row in merged_diagnostic.iterrows():\n",
    "    filecut = row.filecut\n",
    "    file = row.file\n",
    "    if row.Id_Estado_Activo_fixed == 1.0:\n",
    "        final_filename = folder_a + filecut\n",
    "        os.rename(file, final_filename)\n",
    "    if row.Id_Estado_Activo_fixed > 1:\n",
    "        final_filename = folder_b + filecut\n",
    "        os.rename(file, final_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deep learning will need to move the images to\n",
    "# one folder for the two labels. \n",
    "\n",
    "try:\n",
    "    os.mkdir('Data/Export/Wavelets/prediction')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "import os, glob\n",
    "for filename in glob.glob(\"Data/Export/Wavelets/2021*\"):\n",
    "    filename_end = filename.split('/')[-1]\n",
    "    path_pre = \"Data/Export/Wavelets/prediction/\"\n",
    "    final_filename= os.path.join(path_pre, filename_end)\n",
    "    os.rename(filename, final_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('argusenv': conda)",
   "language": "python",
   "name": "python392jvsc74a57bd024562c4dab6fa77a360b373db9a2ca9d2064b61991cc3c4e16141d08a9bf2cc5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
